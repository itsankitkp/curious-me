{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc4ab4b-940b-45ad-8e6a-701e206db80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Desktop\\Proj\\trainer\\venv1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from curious_me import Curious\n",
    "from langchain_openai import ChatOpenAI\n",
    "from getpass import getpass\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38257a46-41fc-4809-a6b0-5004a461c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = getpass('Enter API key')\n",
    "api_key= 'xai-Eg6bNLWl4Vg55zQklEmj06tSy11IYPjUrY1oestiR1RujUWc0wVDzN7KAR3kHAu2WKY1I2afcDC7odRO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d7a89a-2e4c-4b29-9514-55591d349438",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model_name=\"grok-2-1212\",\n",
    "            temperature=0.1,\n",
    "            base_url=\"https://api.x.ai/v1\",\n",
    "            api_key=api_key,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa01190-281b-47ac-9951-f0ec27f5171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['GPT', 'LLM', 'RAG', 'ReLU', 'leaky ReLU', 'activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d8e257-f688-4749-8d00-12e09301d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curious = Curious(topics=topics, llm=llm, skip_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b40c8b-b0ae-42dd-b788-1b3b2fb611f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = curious.ask(\"How can I improve RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81eed96-9dce-4428-9cb8-4ac3758fb12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To improve Retrieval-Augmented Generation (RAG) systems, several strategies can be employed based on the current literature. Here's a structured approach to enhancing RAG, drawing from the key findings and research gaps identified in the literature review:\n",
       "\n",
       "### 1. **Optimize Core Components**\n",
       "\n",
       "**Pre-retrieval, Retrieval, Post-retrieval, and Generation Stages:**\n",
       "- **Advanced Retrieval Strategies:** Implement more sophisticated retrieval methods, such as fine-tuned embedding models, to enhance the relevance of retrieved information. According to [2412.15404v1], advanced retrieval strategies can significantly improve the performance of RAG systems in academic literature navigation.\n",
       "- **Efficient Generation:** Focus on optimizing the generation stage to reduce latency. Studies like [2412.15529v2] suggest that optimizing these stages can lead to better overall performance.\n",
       "\n",
       "### 2. **Integrate Real-World Context**\n",
       "\n",
       "**Real-World Aligned Context Utilization:**\n",
       "- **Practical Implications:** Conduct more studies that align RAG systems with real-world contexts. [2412.17031v1] highlights the need for such studies to understand the practical implications of RAG systems better.\n",
       "- **Domain-Specific Expertise:** Explore the impact of RAG on domain-specific expertise, as this area remains understudied [2412.17031v1].\n",
       "\n",
       "### 3. **Enhance Evaluation Frameworks**\n",
       "\n",
       "**Integrated Evaluation:**\n",
       "- **Synergistic Effects:** Develop evaluation frameworks that consider both retrieval and generation components together to capture their synergistic effects. The disjoint evaluation approach may not fully reflect the capabilities of RAG systems [2412.17031v1].\n",
       "- **RAGAS Framework:** Utilize the Retrieval-Augmented Generation Assessment System (RAGAS) framework to evaluate the effectiveness of RAG systems, particularly in terms of Context Relevance [2412.15404v1].\n",
       "\n",
       "### 4. **Explore New Domains and Technologies**\n",
       "\n",
       "**Diverse Applications:**\n",
       "- **Beyond Data Science and QA:** Investigate the application of RAG in new domains beyond data science and question-answering tasks. This could lead to broader adoption and understanding of RAG's potential [2412.17031v1].\n",
       "- **Synergy with Other AI Technologies:** Research the integration of RAG with other AI technologies to create more robust and versatile systems. This is a promising direction for future research [2412.17031v1].\n",
       "\n",
       "### 5. **Address Latency and Efficiency**\n",
       "\n",
       "**Reducing Latency:**\n",
       "- **Efficient Retrieval Processes:** Enhance the efficiency of retrieval processes to reduce latency, a known challenge in RAG systems [2412.15605v1].\n",
       "- **Simpler Alternatives:** Consider simpler, retrieval-free alternatives like CAG, which may offer comparable or superior results with reduced complexity [2412.15605v1].\n",
       "\n",
       "### Limitations and Considerations\n",
       "\n",
       "While these strategies are based on current research, it's important to acknowledge the limitations in the available evidence:\n",
       "- **Real-World Studies:** There is a lack of comprehensive real-world aligned context utilization studies, which are crucial for understanding the practical implications of RAG systems [2412.17031v1].\n",
       "- **Methodological Gaps:** The disjoint evaluation of retrieval and generation components may not fully capture the synergistic effects of RAG systems [2412.17031v1].\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "Improving RAG systems involves optimizing core components, integrating real-world context, enhancing evaluation frameworks, exploring new domains and technologies, and addressing latency and efficiency. By focusing on these areas, RAG can be further developed to enhance the performance of large language models and provide more accurate and relevant generated content. Future research should aim to fill the identified gaps and continue to push the boundaries of what RAG systems can achieve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ca30d5-70dc-4f14-9510-575d3ef76224",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = curious.get_review(\"RAG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab889b7-b431-4601-b358-e3f69698054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 1. Executive Summary\n",
       "\n",
       "The core research question revolves around the effectiveness and application of Retrieval-Augmented Generation (RAG) systems in various domains. Recent developments in RAG have focused on enhancing context retrieval and generation, with applications spanning healthcare, legal, and education sectors. Key findings indicate that while RAG systems show promise in improving the accuracy and relevance of generated content, there are significant challenges in context utilization and evaluation methodologies, necessitating further research to address these gaps.\n",
       "\n",
       "### 2. Background and Context\n",
       "\n",
       "**Historical Development:**\n",
       "RAG systems have evolved as a response to the limitations of traditional language models, which often suffer from outdated or limited parametric knowledge [2412.17031v1]. The integration of retrieval mechanisms with generative models aims to enhance the accuracy and relevance of generated content by incorporating external, up-to-date information [2412.15404v1].\n",
       "\n",
       "**Key Theoretical Frameworks:**\n",
       "The theoretical underpinning of RAG involves the synergy between retrieval and generation components. The retrieval module is tasked with fetching relevant information, while the generative model must effectively utilize this information to produce coherent and accurate outputs [2412.17031v1]. The RAGAS framework has been utilized for evaluating the quality of generated answers, although it introduces subjectivity into the assessment [2412.15404v1].\n",
       "\n",
       "**Critical Definitions and Concepts:**\n",
       "RAG is defined as a system that combines retrieval of external information with language model generation to produce contextually relevant outputs. Key concepts include context utilization, where the generative model leverages retrieved information, and context retrieval, which involves fetching relevant data from external sources [2412.17031v1, 2412.15404v1].\n",
       "\n",
       "### 3. Main Body Analysis\n",
       "\n",
       "**Detailed Synthesis of Research Findings:**\n",
       "Several studies have highlighted the importance of context retrieval and utilization in RAG systems. For instance, [2412.15404v1] emphasizes the role of prompt design in enhancing LLM performance within RAG, suggesting that well-designed prompts can lead to more contextually aligned answers. Additionally, [2412.14510v1] notes that the requirements for generators in RAG tasks are highly context-dependent, indicating the complexity of meeting all RAG objectives through standard supervised fine-tuning (SFT) alone.\n",
       "\n",
       "**Integration of Multiple Perspectives:**\n",
       "While [2412.15404v1] and [2412.14510v1] focus on the technical aspects of RAG, [2412.17031v1] delves into the broader implications of context usage, suggesting that the success of RAG is influenced by factors beyond what was previously understood. This study also introduces the DRUID resource to facilitate mechanistic and behavioral studies of context usage in real-world scenarios.\n",
       "\n",
       "**Clear Delineation of Agreements and Contradictions:**\n",
       "There is a consensus across studies that RAG systems are valuable for enhancing the accuracy and relevance of generated content [2412.15404v1, 2412.14510v1, 2412.17031v1]. However, contradictions arise in the evaluation methodologies. While [2412.15404v1] uses the RAGAS framework, which introduces subjectivity, [2412.17031v1] questions the generalizability of findings from synthetic datasets, highlighting a need for more real-world aligned studies.\n",
       "\n",
       "**Critical Evaluation of Methodologies Used:**\n",
       "The methodologies employed in RAG research vary, with some studies relying on synthetic datasets [2412.17031v1] and others using custom test sets [2412.15404v1]. The use of the RAGAS framework for evaluation, as noted in [2412.15404v1], introduces a degree of subjectivity, which is a limitation. Additionally, the reliance on pipeline architectures, as discussed in [2412.14510v1], adds complexity but may not fully align with global RAG requirements.\n",
       "\n",
       "### 4. Research Gaps and Future Directions\n",
       "\n",
       "**Identify Understudied Areas:**\n",
       "A significant gap in the current research is the lack of studies that integrate the quality and relevance of retrieved information with the context usage by language models [2412.17031v1]. Additionally, the generalizability of findings from synthetic datasets to real-world scenarios remains under-explored [2412.17031v1].\n",
       "\n",
       "**Highlight Methodological Limitations:**\n",
       "The reliance on synthetic datasets and custom test sets, as well as the subjectivity introduced by evaluation frameworks like RAGAS, are notable limitations in the current research [2412.15404v1, 2412.17031v1]. These limitations suggest a need for more standardized and real-world aligned evaluation methods.\n",
       "\n",
       "**Suggest Promising Research Directions:**\n",
       "Future research should focus on developing standardized evaluation metrics for RAG systems and exploring the integration of retrieval and generation components in a more holistic manner. Additionally, studies that leverage real-world data and scenarios, as suggested by [2412.17031v1], could provide more generalizable insights into RAG performance.\n",
       "\n",
       "### 5. Conclusion\n",
       "\n",
       "**Synthesize Major Themes:**\n",
       "The major themes in RAG research include the importance of context retrieval and utilization, the challenges in meeting RAG objectives through standard methodologies, and the need for more real-world aligned studies. These themes are supported by multiple studies [2412.15404v1, 2412.14510v1, 2412.17031v1].\n",
       "\n",
       "**Assess the Overall State of Research:**\n",
       "The overall state of RAG research is promising but faces significant challenges in evaluation and generalizability. While RAG systems have shown potential in various applications, the field requires further development in methodologies and evaluation standards to fully realize its potential.\n",
       "\n",
       "**Implications for Theory and Practice:**\n",
       "The implications of RAG research for theory include a deeper understanding of context utilization and retrieval mechanisms. For practice, RAG systems can enhance decision-making in fields like healthcare and education by providing more accurate and relevant information. However, the practical application of RAG systems is currently limited by methodological and evaluation challenges that need to be addressed in future research."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d11a508-6755-423a-ad40-3273176f79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = curious.get_citation(claim=\"Leaky ReLU is better than ReLU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7162d73-3bba-4246-a1ff-bf0ee9440738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Analysis of how the evidence supports or challenges the claim:**\n",
       "\n",
       "The provided excerpts from [2409.09981v2] offer substantial evidence supporting the claim that Leaky ReLU is better than ReLU. The primary advantage of Leaky ReLU over ReLU, as highlighted in the excerpts, is its ability to address the \"dying ReLU\" problem. This issue arises when neurons in a neural network using ReLU fail to learn during backpropagation due to negative biases that cause the neuron outputs to be zero, effectively \"killing\" the neuron. Leaky ReLU mitigates this by allowing a small gradient when the input is negative, which helps maintain the learning process for all neurons.\n",
       "\n",
       "The excerpts also provide empirical evidence from a study using the PAUS-GALFORM mock galaxy sample, where Leaky ReLU slightly outperformed ReLU in terms of σRMS and σ68 metrics. This suggests that Leaky ReLU can lead to better performance in certain high-dimensional tasks.\n",
       "\n",
       "However, the excerpts do not provide a comprehensive comparison across all possible scenarios or datasets, which limits the generalizability of the claim. The evidence is specific to the context of the study mentioned, and further research would be needed to confirm the superiority of Leaky ReLU over ReLU in other contexts.\n",
       "\n",
       "**Direct quotes from papers where relevant:**\n",
       "\n",
       "1. From Excerpt 1: \"Leaky ReLU [53] is an improved version of ReLU, specifically designed to address the dying ReLU problem (neuron weights not changing) and has all the advantages of ReLU.\"\n",
       "2. From Excerpt 2: \"To solve this problem, we suggest the use of Leaky ReLU, ELU or GeLU. In our study, we can see that Leaky ReLU slightly outperforms ReLU in σRMS and σ68, as shown in table 4.\"\n",
       "\n",
       "**Clear citations for all evidence:**\n",
       "\n",
       "- [2409.09981v2]\n",
       "\n",
       "**Assessment of the strength of evidence:**\n",
       "\n",
       "The strength of the evidence supporting the claim that Leaky ReLU is better than ReLU is moderate. The excerpts provide a clear theoretical rationale for why Leaky ReLU should be superior, specifically in addressing the dying ReLU problem. Additionally, empirical data from a specific study supports this claim by showing better performance metrics for Leaky ReLU.\n",
       "\n",
       "However, the evidence is limited by its specificity to one study and dataset. The excerpts do not discuss the performance of Leaky ReLU versus ReLU across a broader range of applications or datasets, which would be necessary to fully substantiate the claim. Therefore, while the evidence is compelling within the context of the study cited, more comprehensive research would be needed to generalize the claim across different scenarios."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(citations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
